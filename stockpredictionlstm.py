# -*- coding: utf-8 -*-
"""StockPredictionLSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18Kmvo5H7wYoKELvSaF14oadRuKmDn5LW
"""

import datetime as dt
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import style
import pandas_datareader as web

data =pd.read_csv('/content/sample_data/Tesla.csv')

data = data.sort_values('Date')

data

data.plot()
data.info()

style.use('ggplot')
data['close'] = data['Close']
fig1, ax1 = plt.subplots(figsize=(20,10))
data['close'].plot(ax=ax1)
plt.grid(axis='y')
plt.ylabel("Close")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout, LSTM
from sklearn.preprocessing import MinMaxScaler

""" taking the average of the highest and lowest recorded prices

---


"""

high_prices = data.loc[:,'High']
low_prices = data.loc[:,'Low']
mid_prices = (high_prices+low_prices)/2.0
mid_prices

"""Among whole dataset splitting the training data and test data.
by considering data from 2010 to 2019 for prediction of 2020. Theres length of 2416 rows. where at 2395 theres breakpoint of 2019 data.

---


"""

#train_data = mid_prices[:1197]
#test_data = mid_prices[1198:2394]

"""MinMaxScalar scales all the data to be in the region of 0 and 1 for normalization."""

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1,1))

prediction_days = 60
x_train = []
y_train = []

for x in range(prediction_days, 2394):
  x_train.append(scaled_data[x-prediction_days:x,0])
  y_train.append(scaled_data[x,0])

x_train,y_train = np.array(x_train), np.array(y_train)
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1],1))

#model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(x_train, y_train, epochs=25, batch_size=32)

#Load test data
test_start = dt.datetime(2020,1,1)
test_end = dt.datetime(2020,2,3)

test_data = data.iloc[2396:2416].values
actual_prices = data['Close'].values
#test_data
actual_prices

total_dataset = pd.concat((data['Close'], test_data['Close']),axis=0)

model_inputs = total_dataset[len(total_dataset)-len(test_data)-prediction_days].values
 model_inputs = model_inputs.reshape(-1,1)
 model_inputs = scaler.transform(model_inputs)

x_test = []
for x in range(prediction_days, len(model_inputs)):
  x_test.append(model_inputs[x-prediction_days:x, 0])

x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

predicted_prices = model.predict(x_test)
predicted_prices = scaler.inverse_transform(predicted_prices)

plt.plot(actual_prices, color="black", label=f"Actual price")
plt.plot(predicted_prices, color="green", label=f"Predicted price price")
plt.show()